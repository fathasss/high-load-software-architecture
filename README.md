# High Load System

Ã‡ok fazla kullanÄ±cÄ±dan gelen istekleri hÄ±zlÄ±, gÃ¼venilir ve bozulmadan karÅŸÄ±layabilen sistemlerdir.

1. High Load Sistemlerin Ana Hedefleri

- Scalability (Ã–lÃ§eklenebilirlik): Trafik arttÄ±kÃ§a sistemin Ã§Ã¶kmesi yerine bÃ¼yÃ¼yerek cevap verebilmesidir. (Ã¶rn: Cloud provider)

- Availability (EriÅŸilebilirlik): Sistem Ã§alÄ±ÅŸmaya devam etmeli, kesinti olmamalÄ±.

- Reliability (GÃ¼venilirlik): Veriler kaybolmamalÄ±.

## Realistic Senario:

Diyelim ki kendi URL Shortener sistemimizi yapÄ±yoruz. (bit.ly gibi)

- GÃ¼nlÃ¼k 10 milyar yeni link oluÅŸturuyor.
- GÃ¼nlÃ¼k 2 milyar tÄ±klama geliyor.

Bu ne demek ? 

```
GÃ¼nde 2.000.000.000 tÄ±klama
-> Saniye yaklaÅŸÄ±k 23.148 istek (avarage)
-> Pik zamanlarda bu 5x' e Ã§Ä±kar. ~115.000 istek/saniye
```

ğŸ‘‰ Bu yÃ¼kÃ¼ tek bir sunucu kaldÄ±ramaz. Ä°ÅŸte bu yÃ¼zden High Load mimarisi gerekir.

**High Load Sistemlerin olayÄ± sadece gÃ¼Ã§lÃ¼ donanÄ±m deÄŸil, trafiÄŸi doÄŸru yÃ¶netebilmektir.**

---

# Scaling YÃ¶ntemleri

YÃ¼ksek trafikli sistemler kurgularken ilk bÃ¼yÃ¼k karar ÅŸudur: 

**GÃ¼cÃ¼ artÄ±rarak mÄ± Ã¶lÃ§eceÄŸim, yoksa sayÄ±yÄ± artÄ±rarak mÄ± ?**

1. Vertical Scaling (Scale Up) - "Sunucuyu BÃ¼yÃ¼t"

- Var olan sunucuya daha fazla RAM/CPU/Disk ekliyorsun.
- KolaydÄ±r ama sÄ±nÄ±rÄ± vardÄ±r.

AvantajlarÄ±:
- YÃ¶netmesi kolaydÄ±r. 
- Kodda deÄŸiÅŸiklik gerekmez.

DezavantajlarÄ±: 

- Bir noktadan sonra en bÃ¼yÃ¼k sunucuyu bile satÄ±n alamazsÄ±n.
- Tek bir failure point -> Sunucu Ã§Ã¶kerse tÃ¼m sistem komple gider.

2. Horizontal Scaling (Scale Out) - "Sunucuyu Ã‡oÄŸalt"

- Tek sunucuyu bÃ¼yÃ¼tmek yerine aynÄ± sunucudan 10,100,100 tane koyulmasÄ±.
- Ä°steklerin Load Balancer ile  daÄŸÄ±tÄ±lmasÄ±.

### Load Balancer (YÃ¼k Dengeleyici)

Horizontal Scaling' in kalbi. MÃ¼ÅŸteriden gelen istekleri alÄ±r, sunucularÄ± eÅŸit ÅŸekilde daÄŸÄ±tÄ±r.

```
Client-> Load Balancer -> Server1 / Server2 / Server3

```

**PopÃ¼ler Load Balancer' lar :**

| `YazÄ±lÄ±m BazlÄ±` | `Cloud Managed` |
| --- | --- | 
| nginx,HAProxy |  AWS ELB/ ALB, Google LB, Azure LB  |

> Vertical Scaling neden uzun vadede sÃ¼rdÃ¼rÃ¼lebilir deÄŸildir?

```
Veritical scaling uzun vadeli sÃ¼rdÃ¼rÃ¼lebilir olmamasÄ±nÄ±n sebebi her sunucu bilgisayarÄ±nÄ±n bÃ¼yÃ¼tÃ¼lmesi iÃ§in bir limit olmasÄ±dÄ±r.
```

> Horizontal Scaling kullanÄ±rken tek bir kritik bileÅŸen vardÄ±r â€” o nedir?

```
Horizontal Scaling kullanÄ±rken kritik bileÅŸen Load Balancer' dÄ±r. 
```

> Load Balancer'dan sonra sistemde stateful olmanÄ±n neden sorun olabileceÄŸini tahmin edebiliyor musun?

```
Ã‡Ã¼nkÃ¼ istekler her seferinde farklÄ± sunucuya gidebilir ve sunucu iÃ§inde tutulan session / kullanÄ±cÄ± bilgisi kaybolur.
```

---

# Stateless vs Stateful Sistemler 

Load Balancer ile sunucular Ã§oÄŸaltÄ±ldÄ±ÄŸÄ±nda ÅŸÃ¶yle bir durum oluÅŸur.

```
Client -> Load Balancer -> Server A
Client -> Load Balancer -> Server B
Client -> Load Balancer -> Server C

```

EÄŸer bir kullanÄ±cÄ±yla ilgili oturum (login bilgisi, sepet, geÃ§ici iÅŸlem verisi) sunucunun iÃ§inde saklanmÄ±ÅŸsa buna : 

**Stateful Server** (durum tutan sunucu) denir.

Problem ÅŸudur:

* KullanÄ±cÄ± ilk istekte Server A' ya dÃ¼ÅŸer i login olur (session Server A' da tutulur.)
* Sonraki istek Server B' ye dÃ¼ÅŸerse -> kullanÄ±cÄ± yeniden login olmak zorunda kalÄ±r.

**Ä°ÅŸte bu yÃ¼zden High Load sistemlerde 'State' sunucuda saklanmaz. Ortak bir yere alÄ±nÄ±r.**

Bu sisteme **Stateless Architecture** denir.


> Load Balancer'dan sonra sistemde stateful olmanÄ±n neden sorun olabileceÄŸini tahmin edebiliyor musun?

**Ã‡Ã¶zÃ¼m:**

| `State Saklama Yeri` | `AÃ§Ä±klama`                                                                 |
|  ---                 |  ---                                                                       |
| Redis                | En Ã§ok kullanÄ±lan shared session store                                     |
| Database             | KullanÄ±cÄ± bilgisi DB' de tutulabilir                                       |
| JWT/ Token           | Durumu client tarafÄ±na encode edip geri gÃ¶nderirsin. (sunucu state tutmaz) |

### ğŸ” Bonus: Sticky Session Nedir?

EÄŸer stateless yapÄ± kurmak istemiyorsan Load Balancer' a "Bu kullanÄ±cÄ± hep aynÄ± sunucuya dÃ¼ÅŸsÃ¼n." diyebilirsin. Buna **sticky session/session affinity** denir.

**Ama High Load sistemlerde tavsiye edilmez, Ã§Ã¼nkÃ¼ sunucu Ã¶lÃ¼rse session' da gider.**

Stateful ve Stateless sorununun somut bir Ã¶rneÄŸi

## Ã–rnek E-ticaret Sitesinde Sepet Sistemi:

Sen bir e-ticaret sitesi yapÄ±yorsun (HepsiBurada/ Trendyol gibi). KullanÄ±cÄ± Ã¼rÃ¼ne tÄ±klayÄ±p **sepete ekle** diyor. 

- ğŸ§¨ HatalÄ± Stateful Mimarisi:

```
Client -> Load Balancer -> Server A (Sepeti RAM' de tutuyor.)
```

KullanÄ±cÄ± ikinci Ã¼rÃ¼nÃ¼ eklediÄŸinde: 

```
Client -> Load Balancer -> Server B (Bu sunucuda sepet boÅŸ!)
```

> KullanÄ±cÄ± "Sepetim kayboldu" diye Ã§Ä±ldÄ±rÄ±r. Ã‡Ã¼nkÃ¼ state(durum) sunucuya kilitli kalmÄ±ÅŸtÄ±r.

- âœ… DoÄŸru (Stateless) Mimarisi:

```
Client -> Load Balancer -> Server X -> Sepeti Redis/ DB/ Token' a kayÄ±t eder.
Client -> Load Balancer -> Server Y -> Sepeti Redis' ten okur.
```

**Hangi sunucuya dÃ¼ÅŸerse dÃ¼ÅŸsÃ¼n, client' Ä±n durumu ortak bir yerde tutulur.**

* 1ï¸âƒ£ : Bu Ã¶rnekte State'i merkezi tutmak iÃ§in en mantÄ±klÄ± yer neresi olabilir ? 

1. Database(Sepet tablosu iÃ§ersinde tutmak)
2. Redis(HÄ±zlÄ± cache depolama)
3. JWT Token(Sepeti client tarafÄ±na encode edip cookie iÃ§erisinde taÅŸÄ±mak)

* Cevap : 
```
Ben 2. cevabÄ± seÃ§erdim redis' te tutmak daha mantÄ±klÄ±. Database' de tutmak da mantÄ±klÄ± olabilir.
Ancak tek mantÄ±ksÄ±z olan yol token' da saklamak olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum.
Ã‡Ã¼nkÃ¼ token sÃ¼resinin belirli expire sÃ¼resi var ve bu sÃ¼re belki 1 hafta sonra dolabilir ve sepet datasÄ± kaybolabilir.
```

**Cevap deÄŸerlendirmesi:** 

| `SeÃ§enek`          | `Avantaj`                              | `Dezavantaj`                                                            | `DeÄŸerlendirme`                             |
| ---                | ---                                    | ---                                                                     | ---                                         |
| DB' de saklamak    | KalÄ±cÄ±, gÃ¼venli                        | YavaÅŸ (her sepet aksiyonunda DB sorgusu dÃ¶ner -> yÃ¼k bindirir.)         | MantÄ±klÄ± ama aÄŸÄ±r olabilir.                 |
| Redis' te saklamak | Ã‡ok hÄ±zlÄ±(in-memory) TTL ayarlanabilir.| Redis Ã§Ã¶kse data kaybolabilir -> **ama backup/replication yapÄ±labilir** | Sepet gibi "geÃ§ici state" iÃ§in ideal tercih |
| Token' da saklamak | Sunucusuz, stateless                   | Token ÅŸiÅŸer (bÃ¼yÃ¼k payload), expire olursa sepet kaybolur.              | Riskli                                      |

**Yani Redis, Ã¼Ã§Ã¼nÃ¼n arasÄ±nda en dengeli olanÄ±** -- hem stateless sistemi destekler, hem de yÃ¼ksek trafikte hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.

---

# Cache & Database Stratejileri (Redis+DB Ä°liÅŸkisi)

Bu derste ÅŸu netleÅŸtirilecek.

> "Veri nereye yazÄ±lmalÄ±? Cache nereye, database nereye? Hangisi Ã¶nce okunmalÄ±?"

**3 Ã§eÅŸit cache stratejisi vardÄ±r.**

1. **Read-Through Cache:** Client DB' ye gitmez. -> Cache' e gider. Cache' de yoksa DB' den Ã§eker. (KullanÄ±cÄ± verileri, profil bilgisi vb.)
2. **Write-Through Cache:** YazÄ±lan her veri Ã¶nce cache' e, sonra DB' ye yazÄ±lÄ±r. (KalÄ±cÄ± olmasÄ± gereken data)
3. **Write-Back (Write-Behind):** Veri Ã¶nce sadece cache'e yazÄ±lÄ±r, sonra arkadan DB' ye flush edilir. (Sepet/ Like sistemi gibi geÃ§ici, toleranslÄ± veriler)

Sistem ve kullanÄ±lan cache stratejisi olarak incelersek: 

| `Sistem` | `Cache Stratejisi`|
| --- | --- | 
| User Profile | **Read-Through** (cache varsa ordan oku, yoksa DB' den Ã§ek.) |
| Sepet | **Write-Back** (Redis'te tut -> Db' ye periyodik yazabilirsin veya hiÃ§ yazmayabilirsin.) |
| Banka Bakiyesi | Asla cache yazarken DB' ye gecikmeli gitmemeli -- **Write-Through** yada direkt DB  |

- Cache, verinin kopyasÄ±dÄ±r. Database' in yerine geÃ§mez.
- Redis gibi cache' ler volatile (uÃ§ucu) olabilir; tamamen kritik olan veriler iÃ§in DB garanti noktasÄ±dÄ±r.
- Sepet gibi geÃ§ici ama hÄ±zlÄ± olmasÄ± gereken ÅŸeyleri Redis' te tutmak en makul yoldur.

**Sepet sipariÅŸ mantÄ±ÄŸÄ±nda 'Sepet = geÃ§ici state', 'SipariÅŸ = kalÄ±cÄ± state' olarak deÄŸerlendirilebilir.**

---

# Replication & Consistency (Master-Slave/ Primary-Replica/ Strong vs Eventual)

Åimdi sistemleri Ã§oÄŸalttÄ±k (scaling), cache' e aldÄ±k (Redis). SÄ±radaki soru: 

> Database' i nasÄ±l Ã¶lÃ§eklendiririz?
> Yani High Load altÄ±nda okumalar ve yazmalar nasÄ±l daÄŸÄ±tÄ±lÄ±r? 

## Database Replication Nedir ? 

Bir DB' yi birden fazla kopya olarak tutmak demektir.

**Roller:**
1. Primary(Master): TÃ¼m yazmalar (INSERT/UPDATE) buraya yapÄ±lÄ±r.
2. Replica(Slave/Read Replica): Sadece okumalar yapÄ±lÄ±r.(SELECT) 

Yazma/ Okuma AyrÄ±mÄ± BÃ¶yle Ã‡alÄ±ÅŸÄ±r: 

```
Client(Write) -> Primary DB
Client(Read)  -> Replica DB' ler
```

BÃ¶ylece yÃ¼k paylaÅŸÄ±lmÄ±ÅŸ olur.

âš ï¸ Ancak burada bir sorun var : **Replication Lag**

- Primary DB' ye veri yazÄ±lÄ±r.
- Replica bu veriyi hemen mi alÄ±r? -> *HayÄ±r, Ã§oÄŸu zaman gecikmeli gelir.*

Bu yÃ¼zden ortaya iki tip tutarlÄ±lÄ±k modeli Ã§Ä±kar:

1. **Strong Consistency:** YazÄ±lan veri anÄ±nda tÃ¼m DB' lerde gÃ¶rÃ¼nÃ¼r. (Ã–rn: BankacÄ±lÄ±k Sistemleri) 
2. **Eventual Consistency:** Veriler kÄ±sa sÃ¼reliÄŸine farklÄ± olabilir, ama sonunda eÅŸitlenir. (Ã–rn: Sosyal Medya like sayÄ±larÄ±)

### Eventual Consistency' nin Klasik Ã–rnekleri:

Sen instagramda bir postu like' ladÄ±n.

- Hemen altta "12502 -> 12503 beÄŸeni" olur.
- ArkadaÅŸÄ±n telefonunda hala 12502 gÃ¶rÃ¼nÃ¼yor.

**Bu bir bug deÄŸil eventual consistency' dir.**

* 1ï¸âƒ£: Bir e-ticaret sitesinde "Ã¼rÃ¼n stok sayÄ±sÄ±" sence hangi modelle tutulmalÄ±? (Strong mu, Eventual mÄ±?) Neden ? 

* Cevap: Bir e-ticaret sitesinde Ã¼rÃ¼nÃ¼n stok sayÄ±sÄ± strong consistency ile tutulabilir. 
          Ã‡Ã¼nkÃ¼ sepete ekleyip sipariÅŸ verildiÄŸinde eÄŸer bir gecikme yaÅŸanÄ±rsa sonrasÄ±nda sipariÅŸin iptali gibi
          mÃ¼ÅŸterilerde olumsuz durumlara yol aÃ§ma riski vardÄ±r.

* 2ï¸âƒ£: **KullanÄ±cÄ± profiline ait gÃ¶sterilen takipÃ§i sayÄ±sÄ±** sence strong consistency mi gerektirir yoksa eventual olabilir mi?

* Cevap: KullanÄ±cÄ± profiline ait gÃ¶sterilen takipÃ§i sayÄ±sÄ± eventual consistency ile iÅŸlem yapÄ±lmasÄ± daha saÄŸlÄ±klÄ± olur. 
         Ã‡Ã¼nkÃ¼ 1. cevapdaki gibi Ã§ok Ã§ok olumsuz durumlara ve sonrasÄ±nda yaÅŸanacak krizlere sebebiyet verecek bir Ã¶ncelik olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

**Kritik olmayan datalarda Eventual Consistency, kritik datalarda Strong Consistency seÃ§imi yapÄ±lÄ±r. High Load sistem tasarÄ±mÄ± tam da bu dengeyi kurmak demektir.**

---

# Partitioning/ Sharding (GerÃ§ek Ã–lÃ§eklenme Burada BaÅŸlar.)

Cache ekledik. Replication yaptÄ±k ama bir noktada tek bir Primary DB bile yetmeyecek.

Ä°ÅŸte bu durumda yapÄ±lacak ÅŸey: 

> Database'i bÃ¶lmek.

## Partitioning/ Sharding Nedir? 

**Devasa bir tabloyu veya database' iki ya da daha fazla parÃ§aya bÃ¶lmek.**

BÃ¶ylece:

```
instread of -> 1 DB with 1M users
we do -> 10 DB each with 10K users
```

### Sharding YÃ¶ntemleri:

1. **Range Sharding:** Alfabetik veya ID aralÄ±ÄŸÄ±na gÃ¶re *(Ã–rn: A-M -> DB1, N-Z -> DB2)*
2. **Hash Sharding:** ID' yi hash' leyip mod alarak *(Ã–rn: user_id % 4 -> 4 farklÄ± shard)*
3. **Geo Sharding:** Lokasyona gÃ¶re *(Ã–rn: Avrupa ayrÄ± DB, Amerika ayrÄ± DB)*
4. **Feature/Entity Based:** Veri tipine gÃ¶re *(Ã–rn: dbo.Users tablosu farklÄ±, dbo.Orders farklÄ± DB' de )*

* Ã–rnek: KullanÄ±cÄ±larÄ± Hash ile Shard Et:

```
Shard = user_id % 4 

user_id = 341 => 341 % 4 = 1 -> Database A 
user_id = 762 => 762 % 4 = 2 -> Database B

```

**Her sunucu sadece kendi parÃ§asÄ±nÄ± bilir -> yÃ¼k daÄŸÄ±tÄ±lÄ±r,sorgular hÄ±zlanÄ±r.**

**Sharding SorunlarÄ±:**

1. **Cross-Shard Query:** "Bir kullanÄ±cÄ±nÄ±n 5 sipariÅŸi, 3 yorumu ve 2 adresi var." -> hepsi farklÄ± DB' de ise toplamak zorlaÅŸÄ±r.
2. **Shard Rebalancing:** "Shard 1 Ã§ok doldu,2 boÅŸ kaldÄ±" gibi durumlarda yeniden daÄŸÄ±tÄ±m gerektirir.
3. **ID Uniqueness:** FarklÄ± shard' lardaki veriler Ã§akÄ±ÅŸabilir. -> *global_id* sistemi gerekebilir.

* 1ï¸âƒ£: Sence â€œKullanÄ±cÄ± tablosuâ€nu sharding yapmak mantÄ±klÄ±dÄ±r ama â€œÃœrÃ¼n kategorileriâ€ tablosunu sharding yapmak mantÄ±klÄ± mÄ±dÄ±r? Neden?

* Cevap: Bence Ã¼rÃ¼n kategorileri tablosunu sharding yapmak Ã§ok deÄŸildir. Ã‡Ã¼nkÃ¼ kategorilerin mutlak bir sÄ±nÄ±rÄ± vardÄ±r. Bu yÃ¼zden datanÄ±n bÃ¶lÃ¼nmesi gerektiÄŸini dÃ¼ÅŸÃ¼nmÃ¼yorum.

* 2ï¸âƒ£: Sharding yapÄ±ldÄ±ÄŸÄ±nda "user_id = 1234" iÃ§in hangi shard kullanÄ±labileceÄŸini nasÄ±l bilebiliriz. (Senin Ã¶nerdiÄŸin yÃ¶ntem)

* Cevap: Ã‡ok bÃ¼yÃ¼k bir trafik dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde mesela amazon gibi. Ã–nce Geo Sharding yÃ¶ntemi ile bÃ¶lgelere ayÄ±rÄ±p ardÄ±ndan aynÄ± bÃ¶lgelerdeki kullanÄ±cÄ±lar iÃ§in de Hash Sharding kullanarak daha verimli bir bÃ¶lÃ¼mleme ile sistemin daha stabil ve hÄ±zlÄ± Ã§alÄ±ÅŸabileceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.
Mesela TÃ¼rkiye' de kayÄ±t olan bir amazon kullanÄ±cÄ±sÄ± Geo Sharding yÃ¶ntemi ile TR sunucularÄ±na kayÄ±t olacak ardÄ±ndan TR' de bulunan istanbul, Ankara veya Ä°zmir gibi illerde bulunan sunucularÄ±nda Hash Sharding kullanarak veri paylaÅŸÄ±mÄ± yapmak daha saÄŸlÄ±klÄ± olabilir. Cevap Amerika iÃ§in yine Amazon gibi yÃ¼ksek trafikli bir sistemden bahsedecek olursak ilk olarak Geo sharing ile kÄ±ta bazlÄ± ABD sunucusu olarak bÃ¶ler sonrasÄ±nda yine Geo sharding ile bu sefer ABD iÃ§erisindeki sunucularÄ± eyalet bazlÄ± bÃ¶lerdim ve eyalatlerde bulunan sunucularÄ± Hash Sharding ile bÃ¶lmeyi dÃ¼ÅŸnÃ¼rdÃ¼m. Mesela Washington iÃ§in aktif 30 sunucu varsa bu 30 sunucu da Hash Sharding yÃ¶ntemi uygulardÄ±m. 

> **EÄŸer data Ã§ok kÃ¼Ã§Ã¼kse -> bÃ¶lmek yerine tÃ¼m sunuculara kopyalamak daha mantÄ±klÄ±dÄ±r. (Replication)**

> **EÄŸer data bÃ¼yÃ¼kse -> parÃ§alamak zorundayÄ±z. (Sharding)**

---

# Message Queues & Asenkron Ä°ÅŸlem (Event Driven Architecture)

## âœ… Message Queue Nedir?

> Ãœretilen olaraylarÄ± (event) *hemen iÅŸlemek sÄ±raya koymak* ve asenkron **(gecikmeli ama garantili)** ÅŸekilde iÅŸlemek iÃ§in kullanÄ±lan sistemdir.

### ğŸ“ŒNeden KullanÄ±lÄ±r?

Ã‡Ã¼nkÃ¼ gerÃ§ek dÃ¼nyada bazÄ± iÅŸlemler hemen yapÄ±lmak zorunda deÄŸildir.

| `Ä°ÅŸlem` | `Senkron Durumu` |
| --- | --- |
| KullanÄ±cÄ± 'Pay' butonuna bastÄ± - > Ã–deme OnayÄ± | Senkron olmalÄ±(Hemen cevap vermeli) |
| Ã–demeden sonra 'Mail GÃ¶nder' | Asenkron (SÄ±ra kuyruÄŸa yaz, arkadan iÅŸlenir.) |
| Like sayÄ±sÄ±nÄ± artÄ±r | Asenkron yapÄ±labilir | 
| KullanÄ±cÄ±ya bildirim gÃ¶nder | KuyruÄŸa atÄ±labilir |
| bÃ¼yÃ¼k resmi sÄ±kÄ±ÅŸtÄ±r. | KuyruÄŸa at |

### Queue Kullanmazsan Ne Olur ?

Ã–rnek: 

```
POST /buy

-> DB insert
-> Stok azalt
-> Mail gÃ¶nder
-> PDF Fatura oluÅŸtur
-> Bildirim gÃ¶nder
-> Slack mesajÄ± gÃ¶nder
```

Hepsini aynÄ± anda yaparsan 5 saniye sÃ¼rer. KullanÄ±cÄ± "bozuldu mu?" diye sayfayÄ± kapatÄ±r.

### Queue ile DoÄŸru Mimari

```
POST /buy
-> DB insert + Stok dÃ¼ÅŸ (sadece ana iÅŸlem)
-> Event "OrderCreated" kuyruÄŸa yazÄ±lÄ±r
-> Worker' lar arkadan: Mail, Fatura, Bildirim, Slack gÃ¶nderir.
```

KullanÄ±cÄ±ya cevap verilir. -> **SipariÅŸ AlÄ±ndÄ±**

Arka planda herÅŸey devam eder.

**Message Queue Ã–rnekleri:**

| `Sistem` | `Type` | `KullanÄ±m` |
| --- | --- | --- |
| RabbitMQ | Message Broker | KÃ¼Ã§Ã¼k-Orta Sistemler |
| Kafka | Event Streaming | YÃ¼ksek throughput -> 1M+ events | 
| AWS SQS, GCP Pub/Sub | Cloud Queue | Serverless kullanÄ±m |
| Redis Stream | Lightweight Queue | Basit Ä°ÅŸler iÃ§in |

* 1ï¸âƒ£: Bir e-ticaret sitesinde "SipariÅŸ verildiÄŸinde mail gÃ¶nderme" iÅŸlemi sence Senkron mu olmalÄ±, Asenkron mu? Neden ?

* Cevap: Bence asenkron olmalÄ±. Senkron bir sipariÅŸ akÄ±ÅŸÄ± tasarlanmÄ±ÅŸ ve canlÄ± data yazÄ±lmÄ±ÅŸ. KullanÄ±cÄ± artÄ±k sipariÅŸini vermiÅŸ ve gerekli stok iÅŸlemleri yapÄ±lmÄ±ÅŸ. Bu yÃ¼zden mail kullanÄ±cÄ± iÃ§in bir ek bilgilendirme. KuyruÄŸa alÄ±nÄ±p bekletilebilir.

* 2ï¸âƒ£: Like butonuna basÄ±ldÄ±ÄŸÄ±nda sayacÄ± hemen artÄ±rmak mÄ± gerekir, yoksa Queue' ya atÄ±p gecikmeli artÄ±rmak da olur mu? 

* Cevap: Ä°lk sayaÃ§ iÅŸlemi cache' de yapÄ±lÄ±p cache' deki sayacÄ±n artÄ±lÄ±rÄ±lÄ±p canlÄ± yazma iÅŸlemi asenkron yapÄ±lmasÄ± daha saÄŸlÄ±klÄ± olur. Ã‡Ã¼nkÃ¼ Ã¼nlÃ¼ bir influencer' Ä±n sosyal medya postu saniyeler iÃ§erisinde Ã§ok fazla trafik alabilir. Bu yÃ¼zden canlÄ± data olarak aktarma iÅŸlemi asenkron olarak yapÄ±lmasÄ± ve kuyruk yapÄ±sÄ± ile kurgulanmasÄ± daha saÄŸlÄ±klÄ± olur. 

**Ä°kinci sorunun cevabÄ± iÃ§in "Burst Traffic" ihtimalinin dÃ¼ÅŸÃ¼nÃ¼lmÃ¼ÅŸ olmasÄ± gayet mantÄ±klÄ±. BÃ¼yÃ¼k sistemler (Instagram, Twitter) exactly this! yÃ¶ntemini kullanmaktadÄ±r.**

---

# Eventual Consistency GerÃ§ek DÃ¼nyada NasÄ±l YÃ¶netilir?

Consistency konusuna Ã¶nce teorik olarak baktÄ±k ama ÅŸimdi eventual consistency ile yapÄ±lan tutarsÄ±zlÄ±klar nasÄ±l yÃ¶netilir kÄ±smÄ±na geÃ§elim.

## Senaryo:

Bir e-ticaret sitesindesin.

- KullanÄ±cÄ± SipariÅŸi Verdi -> Ã–deme AlÄ±ndÄ± âœ…
- Ama arkaplanda Ã§alÄ±ÅŸan asenkron iÅŸlemlerden biri **BAÅARISIZ** oldu. (Ã¶rneÄŸin stok gÃ¼ncellemesi yapmadÄ±.)

| `Strateji` | `AÃ§Ä±klama` | `Risk` |
| --- | --- | --- | 
| Strong Consistency (Transactional) | TÃ¼m adÄ±mlar aynÄ± anda yapÄ±lÄ±r, biri fail olursa geri alÄ±nÄ±r. | KullanÄ±cÄ± bekler, yavaÅŸlatÄ±r. |
| Eventual Consistency + Retry Queue | BaÅŸaramayan event tekrar kuyruÄŸa atÄ±lÄ±r ve yeniden denenir. | BazÄ± event' lar *eninde sonunda* olur ama geÃ§ olabilir. |
| SAGA Pattern (Compensating Action) | **EÄŸer stok gÃ¼ncellemesi baÅŸarÄ±sÄ±z ise -> SipariÅŸi otomatik iptal et ve parayÄ± geri Ã¶de.** | KullanÄ±cÄ±yÄ± Ã¼zmeden rollback. |

## SAGA Pattern (DaÄŸÄ±tÄ±k TransactionlarÄ±n KurtarÄ±cÄ±sÄ±)

| `Step` | `Process` | `Is Success?` | 
| --- | --- | --- |
| 1 | Payment-> Success | Compensate: Para iadesi | 
| 2 | Stok dÃ¼ÅŸ | Compensate: Stok Geri Ekle | 
| 3 | SipariÅŸi DB' ye yaz | Compensate: SatÄ±r sil |
| 4 | Mail gÃ¶nder | (Gerek yok, sadece logla) | 

* 1ï¸âƒ£ Eventual consistency kullanÄ±lan sistemlerde â€œbaÅŸarÄ±sÄ±z eventâ€™lerâ€ iÃ§in nasÄ±l bir strateji uygulanmalÄ±dÄ±r? Retry mi, kompanzasyon mu, loglayÄ±p bÄ±rakmak mÄ±? Sen nasÄ±l karar verirsin?

* Cevap: BaÅŸarÄ±sÄ±z event' lar iÃ§in transactional iÅŸlem uygulanabilir. Bir sipariÅŸin verildiÄŸini varsayalÄ±m. Ã–deme ve Stoktan dÃ¼ÅŸme iÅŸlemi Strong Consistency yapÄ±sÄ± ile yapÄ±lmÄ±ÅŸ olsun.
Kuyruk yapÄ±sÄ± kullanÄ±larak mail gÃ¶nderme gibi iÅŸlemler sÃ¶z konusu. Kuyrukda hata alÄ±ndÄ±ÄŸÄ±nda mail gÃ¶nderme, fatura kesme gibi iÅŸlemler SAGA Pattern ile yapÄ±labilir.
Yada yalnÄ±zca Ã¶deme adÄ±mlarÄ± Strong Consistency ile yapÄ±ldÄ±ysa. Stoktan dÃ¼ÅŸme, mail gÃ¶nderme ve fatura gÃ¶nderme gibi iÅŸlemlerde SAGA Pattern kullanÄ±larak iÅŸlemler geri alÄ±nabilir sipariÅŸ iptal edilip para iadesi saÄŸlanabilir. Ä°ki yolda saÄŸlÄ±klÄ±dÄ±r. 

* 2ï¸âƒ£ Sence bir bankacÄ±lÄ±k sisteminde â€œpara transferiâ€ eventual consistency olabilir mi? Yoksa strong mu olmak zorunda?

* Cevap: Bence bir bankacÄ±lÄ±k sisteminde para transferi iÅŸlemi kuyruk yapÄ±sÄ± ile yapÄ±lmalÄ±. Yani Eventrual Consistency ve denenebilir kuyruk yapÄ±sÄ± kullanÄ±labilir. Ã‡Ã¼nkÃ¼ bankacÄ±lÄ±k sistemlerinde para transferi yapÄ±lÄ±rken istek yapÄ±lan servislerde farklÄ± farklÄ± sorgulama servisleri Ã§alÄ±ÅŸabilir ve bu trafiÄŸin yÃ¶netilmesi iÃ§in Eventual Consistency daha uygundur.

---

# Read-Heavy Trafikte Replication & CQRS

### Problem:

Bir sistemde: 

1. %10 Write (INSERT /UPDATE/ DELETE)
2. %90 Read (SELECT)

yapÄ±lÄ±yor olsun.

Bu durumda bÃ¼tÃ¼n read isteklerini primary database' den yapmak mantÄ±klÄ± mÄ±dÄ±r ? 

> HayÄ±r. Ã‡Ã¼nkÃ¼ primary sÃ¼rekli yazma da yapÄ±yor. -> Okuma yÃ¼kÃ¼ geldiÄŸinde yavaÅŸlar.

### Ã‡Ã¶zÃ¼m:

| `Veri` | `Nereden okunur?` | `Nereden yazÄ±lÄ±r?` | 
| --- | --- | --- |
| Yazma iÅŸlemi (CREATE/ UPDATE) | -> Primary DB | âœ… | 
| Okuma iÅŸlemi (GET/ LIST) | -> Read Replica DB | âœ… |

Bu yapÄ±ya Ã§oÄŸu zaman CQRS (Command Query Responsibility Segregation) denir. 

**Mimari:**

```
        WRITE   
App -------------> Primary DB
|
READ
|
-----------------> Read-Replica-1
|
-----------------> Read-Replica-2
```

* 1ï¸âƒ£ Sadece **read heavy** olan bir endpoint (Ã¶rneÄŸin: Trend Ã¼rÃ¼nleri listeleme) hangi DBâ€™den okunmalÄ±? Primary mÄ±, Replica mÄ±?

* Cevap: Trend Ã¼rÃ¼nleri listelemek farklÄ± replica  database'lerden okunmasÄ± daha saÄŸlÄ±klÄ± olur. Ã‡Ã¼nkÃ¼ trend Ã¼rÃ¼nler belirli ortalamaya gÃ¶re deÄŸiÅŸiklik gÃ¶sterebilir. DeÄŸiÅŸen bir veri olduÄŸu iÃ§in Replica' dan okumak daha saÄŸlÄ±klÄ± olabilir. 

* 2ï¸âƒ£ Replicaâ€™dan okuduÄŸumuz iÃ§in â€œanlÄ±k deÄŸiÅŸiklikleri 1-2 saniyelik gecikmeyle gÃ¶rÃ¼rsekâ€ bu problem olur mu? Hangi senaryoda sorun olur, hangi senaryoda olmaz?

* Cevap: Sorun olabilecek senaryolardan bir tanesi anlÄ±k Ã§ok hÄ±zlÄ± deÄŸiÅŸen veriler. Mesela like sayÄ±larÄ± ya da Ã¼nlÃ¼ influencer' Ä±n yaptÄ±ÄŸÄ± paylaÅŸÄ±mÄ±n altÄ±nda gelen yorumlar veya reddit gibi platformlarda aÃ§Ä±lmÄ±ÅŸ trend konularda etkileÅŸimlerin yavaÅŸlamasÄ±nÄ± saÄŸlayabilir. Bu noktada Redis gibi bir yapÄ±nÄ±n kullanÄ±lmasÄ± daha saÄŸlÄ±klÄ± olur.

```
Primary DB(Write) -> DoÄŸru ve GÃ¼Ã¼ncel Veri -> Ani yÃ¼kte zorlanÄ±r -> Ã–deme,Stok dÃ¼ÅŸme
Read Replica -> Read' i Ã¶lÃ§eklendirir -> 1-3 saniye gecikmeli olabilir -> Profil gÃ¶rÃ¼ntÃ¼leme, Trend Ã¼rÃ¼n listesi
Redis Cache -> Ultra HÄ±zlÄ± Okuma -> Veri eski olabilir -> Like sayÄ±sÄ±, Hot Content
```

> HerÅŸey DB' den **okunmaz**, her veri **aynÄ± ciddiyette deÄŸildir.**

---

# Rate Limiting & Throttling (KullanÄ±cÄ±larÄ± ve BotlarÄ± Kontrol Etme)

> Bir kullanÄ±cÄ± (veya bot) saniyede 1000 istek atarsa ne yaparsÄ±n ? 

1. **Rate Limit:** Belirli bir sÃ¼re iÃ§inde bir kaynaÄŸa kaÃ§ kez eriÅŸilebileceÄŸini kontrol eder. (1 IP -> dakikada en fazla 30 Login denemesi)
2. **Throttling:** Limit aÅŸÄ±lÄ±rsa istekleri tamamen engellemek yerine yavaÅŸlatÄ±r. (Videoyu 1080P deÄŸil 480P vermek)
3. **Quota:** KullanÄ±cÄ±ya uzun dÃ¶nemli bir limit verir.  (Free User -> Ayda 5000 API Ã§aÄŸrÄ±sÄ±)

## Rate Limiti NasÄ±l UygularÄ±z ? 

Rate limit uygulanabilecek 4 farklÄ± katman bulunur.

1. **Client Side (UI):**  "Bu butona hÄ±zlÄ± basmayÄ±n" uyarÄ±sÄ± -> ZayÄ±f ama iyi UX
2. **Backend Gateway/ API Gateway:** NGINX, Envoy, Kong, AWS API Gateway -> En sÄ±k kullanÄ±lan katman
3. **Middleware/ Code Level:** Express/ Nest/ Spring interceptor -> Esnek ama app yÃ¼klenir
4. **Firewall/ Network Level:** Cloudflare, AWS WAF -> Botlara karÅŸÄ± en etkili

> **GerÃ§ek dÃ¼nya sistemlerinde Rate limit genelde Redis + Sliding Window/ Token Bucket algoritmasÄ±yla yapÄ±lÄ±r.**

* 1ï¸âƒ£ Bir login endpointâ€™i iÃ§in Rate Limiting uygulanmalÄ± mÄ±? NasÄ±l bir limit koyardÄ±n?

* Cevap: Evet. Login endpoint' i iÃ§in bir Rate Limit kullanÄ±rdÄ±m. Ã‡Ã¼nkÃ¼ kaba kuvvet saldÄ±rÄ±sÄ±na maruz kalabilir. Bunun iÃ§inde saniyede login endpoint'i iÃ§in bir limiti olurdu ve bu limit aÅŸÄ±ldÄ±ÄŸÄ±nda gelen isteÄŸin IP' sini kara listeye alÄ±rdÄ±m. 

* 2ï¸âƒ£ APIâ€™yi kullanan premium ve free kullanÄ±cÄ±larÄ± farklÄ± ÅŸekilde sÄ±nÄ±rlamak ister misin? NasÄ±l?

* Cevap: Evet sÄ±nÄ±rlamak isterim. API' nin Premium sÃ¼rÃ¼mÃ¼ iÃ§in ayda 100.000 API Ã§aÄŸrÄ±sÄ± alabilecek ÅŸekilde sÄ±nÄ±rlandÄ±rÄ±rÄ±m. AyrÄ±ca Free sÃ¼rÃ¼mÃ¼ iÃ§inde aylÄ±k 10.000 istek ile kÄ±sÄ±tlardÄ±m.

---

# Token Bucket AlgoritmasÄ±

Rate limiting sistemlerde en Ã§ok kullanÄ±lan algoritma: 

> Token Bucket (ve varyasyonu: Leaky Bucket)

## Token Bucket MantÄ±ÄŸÄ±

Her kullanÄ±cÄ±ya bir bucket (kova) veriyoruz.

| `Kova Ã¶zelliÄŸi` | `AnlamÄ±` |
| --- | --- |
| Kova kapasitesi (capacity) | Maksimum kaÃ§ istek hakkÄ± birikebilir ? |
| Token refill rate | Her saniye ne kadar yeni hak veriyoruz ? |
| Request GeldiÄŸinde | Kovada token varsa -> Ä°zin verilir ve 1 token dÃ¼ÅŸÃ¼rÃ¼lÃ¼r. Yoksa -> Reddedilir veya bekletilir. |

* Ã–rnek (Free KullanÄ±cÄ±)

| `Ã–zellik` | `DeÄŸer` |
| --- | --- |
| Capacity | 100 Token |
| Refill Rate | 1 token/ saniye (yani dakikada 60 istek)

* KullanÄ±cÄ± bir anda 100 istek atabilir. (kovada doluysa)
* Ama sÃ¼rekli atmak isterse en fazla 60 istek/ dakika yapabilir.

* Ã–rnek (Premium KullanÄ±cÄ±) 

| `Ã–zellik` | `Free` | `Premium` | 
| --- | --- | -- |
| Capacity | 100 Token | 1000 token |
| Refill Rate | 1 t/s | 10 t/s|

* ğŸ‘‰ Login endpointâ€™i iÃ§in hangi rate limiting modelini seÃ§erdin?

1. Sliding Window (Zaman aralÄ±ÄŸÄ±nda sabit limit â€” Ã¶rn: 5 dakika iÃ§inde en fazla 10 login denemesi)
2. Token Bucket (Saniyede 1 token â€” anlÄ±k patlamaya izin verir ama sÃ¼rdÃ¼rÃ¼lebilir deÄŸilse keser)
3. Fixed Window (Her 1 dakikada bir limit sÄ±fÄ±rlanÄ±r)

* Cevap: EÄŸer yalnÄ±zca bir tanesini kullanacak isem Sliding Window rate limit modelini seÃ§erdim. Ã‡Ã¼nkÃ¼ brute force karÅŸÄ± daha Ã¶nemli bir yÃ¶ntem olurdu. Ama eÄŸer birden fazla kullanacaksam Sliding Window ve Token Bucket yÃ¶ntemlerini bir arada kullanabilirdim. Login endpoint' i iÃ§in belirli sayÄ±da bir token olurdu mesela 3 token. Ä°lk 3 denemede parolayÄ± hatÄ±rlamadÄ±ysa kullanÄ±cÄ± Token Bucket' ta login endpoint iÃ§in olan istekleri sÄ±fÄ±rlardÄ±m ve iki adÄ±mlÄ± doÄŸrulama kullanmasÄ±nÄ± isterdim. Burda da aÅŸÄ±rÄ± istek oluyorsa ÅŸayet sliding window ile belirlediÄŸim limite gÃ¶re baÄŸlantÄ±yÄ± kapatÄ±rdÄ±m. 

# Circuit & Breaker Failover

* Neden Gerekli ?

Bir servise ya da dÄ±ÅŸa baÄŸÄ±mlÄ± bir kaynaÄŸa sÃ¼rekli baÅŸarÄ±sÄ±z istek atmak tÃ¼m sistemi yavaÅŸlatÄ±r veya Ã§Ã¶kertir. **Circuit Breaker** bu tÃ¼r aksaklÄ±klarda aracÄ± olarak davranÄ±r: belirli bir baÅŸarÄ±sÄ±zlÄ±k eÅŸiÄŸine gelince daha fazla istek gÃ¶ndermeyi keser, sistemin geri kalanÄ±nÄ± korur. Failover ise arÄ±zalÄ± servisten trafiÄŸi baÅŸka saÄŸlÄ±klÄ± servise yÃ¶nlendirmektir.

## Temel Kavramlar

1. **Timeouts:** Her isteÄŸin makul bir sÃ¼re iÃ§inde geri dÃ¶nmediÄŸni dÃ¼ÅŸÃ¼nerek zaman aÅŸÄ±mÄ± koyar.
2. **Retries with Backoff:** Hata alÄ±ndÄ±ÄŸÄ±nda hemen tekrar denemek yerine artan gecikme (exponential backoff + jitter) uygula.
3. **Circuit Breaker States:** 
* Closed : Normal durum istekler gÃ¶nderilir.
* Open: Hatalar yÃ¼ksek -> istekler reddedilir kÄ±sa sÃ¼reliÄŸine.
* Half-Open: Belirli aralÄ±k sonra az sayÄ±da deneme gÃ¶nderilir; baÅŸarÄ±lÄ±ysa Closed' a dÃ¶ner, baÅŸarÄ±sÄ±zsa tekrar Open.
* Bulkhead: KaynaklarÄ± bÃ¶lÃ¼mlere ayÄ±r; bir bÃ¶lÃ¼m Ã§Ã¶kse diÄŸerleri Ã§alÄ±ÅŸmaya devam eder. (Ã¶rn: thread pool' lar).
* Failover/ Graceful Degradation: Bir hizmet Ã§Ã¶ktÃ¼ÄŸÃ¼nde alternatif servis, cached response veya degraded ux sun.

### Tipik Circuit Breaker KurallarÄ± (pratik)

* windowSize: son N istekte ne kadar hata yoksa?
* failureThreshold: % hata oranÄ± (Ã¶rn. %50) veya hatalÄ± istek sayÄ±sÄ± (Ã¶rn. 20) aÅŸÄ±lÄ±rsa -> Open
* openTimeout: Open durumunda bekleme sÃ¼resi (Ã¶rn. 30s).
* halfOpenMaxCalls:  Half-open' dayken kaÃ§ istek test edilecek. (Ã¶rn. 5).
* successThreshold: Half-open testlerde kaÃ§ baÅŸarÄ±lÄ± istek ÅŸart (Ã¶rn. 3) -> Closed.

**Ã–rnek: PseudoCode (basit circuit breaker)**

```pseudo

class CircuitBreaker{
        state = "CLOSED"
        failures = 0
        successCount = 0
        lastFailure = null

        onRequest(call):
            if state == "OPEN":
                if now-lastFailureTime < OPEN_TIMEOUT:
                    throw CircuitOpenException
                else:
                    state = "HALF_OPEN"
                    successCount = 0

            try:
                resp = call()
                onSuccess()
                return resp
            except Exception:
                onFailure()
                throw

        onSuccess():
            if state == "HALF_OPEN":
                successCount += 1
                if successCount >= SUCCESS_THRESHOLD:
                    state = "CLOSED"
                    failures = 0
                else:
                    failures = 0

        onFailures():
            failures += 1
            lastFailuretime = now
            if  failures > FAILURE_THRESHOLD:
                state = "OPEN"
}

```
### Retries & Backoff (iyi uygulama)

1. **MaxRetries:** 3
2. **Backoff:** exponential (e.g., 100ms,  200ms, 400ms)
3. **Jitter:** kÃ¼Ã§Ã¼k rastgeleleÅŸtirme ekle, thundering herd Ã¶nlenir.
4. **Idempotency:** retry edilebilecek Ã§aÄŸrÄ±lar idempotent olmalÄ± veya idempotency-key kullanÄ±lmalÄ±. (Ã¶rn: Ã¶deme iÅŸlemleri iÃ§in)

### Failover & Routing

1. **Active-Passive:** Primary' den hata alÄ±ndÄ±ÄŸÄ±nda Secondary' ye yÃ¶nlendir.
2. **Active-Active:** Trafik her iki bÃ¶lgeye de gider; bir bÃ¶lge dÃ¼ÅŸerse diÄŸerleri kalÄ±r.
3. **Geo-Failover:** BÃ¶lge dÃ¼ÅŸerse DNS veya global Load Balancer ile trafiÄŸi baÅŸka bÃ¶lgeye taÅŸÄ±.

Ã–rnek : DB read-replicas -> read from nearest replica; primary fail olursa promote replica veya route clients to other region.

### Bulkhead & Resource Isolation

- Her dÄ±ÅŸ API iÃ§in ayrÄ± thread pool veya connection pool kullan.
- bir API yoÄŸunlaÅŸÄ±rsa diÄŸer API' nin kaynaklarÄ±nÄ± yemez.

### Graceful Degradation (KullanÄ±cÄ±ya nasÄ±l davranÄ±rÄ±z?)

EÄŸer bir microservis dÃ¶nmÃ¼yorsa:

- Serve cached data (Ã¶nbellekleki son iyi sonuÃ§)
- Minimal/ degraded UI (Ã¶rn. "ÅŸu an yorumlar yÃ¼kleniyor")
- Fail-fast: uzun bekletme yerine hÄ±zlÄ± fallback dÃ¶ndÃ¼rÃ¼r.

### Monitoring & Metrics (mutlaka izle)

Her circuit breaker iÃ§in:

- requestRate
- errorRate
- latency (P50/ P95/ P99)
- state changes (Open->Half Open-> Closed)
- retry count
- downstream latency

UyarÄ±lar(alert):

- Circuit Breaker open sayÄ±sÄ± artarsa (yÃ¼zde veya absolut)
- Latency P95 > hedef
- Retries > threshold

**GerÃ§ek Hayatta KullanÄ±m Ã–rnekleri:**

- Netflix Hystrix(eski) -> circuit breaker implementasyonu Ã¼nlÃ¼dÃ¼r.
- Envoy ve Istio gibi servis mesh' ler circuit breaker, retries ve timeouts saÄŸlar.
- API Gateway (NGINX, Kong, AWS API GW)

### Ã–rnek Senaryo: Ã–deme Servisi:

1. KullanÄ±cÄ± Ã¶deme yapar. -> call PaymentService()
2. EÄŸer PaymentService timeout veya hata verirse: 
- Retry(Maks 3) exponential backoff ile.
- EÄŸer CB aÃ§Ä±ldÄ±ysa: fallback-> "Ã–deme iÅŸleminiz ÅŸuan yavaÅŸ. LÃ¼tfen faha sonra tekrar deneyin veya destek ile iltiÅŸime geÃ§in."
- Background: enqueue event for manual investigation or retry.

AyrÄ±ca Ã¶deme iÃ§in idempotency-key kullanÄ±lmalÄ±, tekrar Ã§aÄŸrÄ±da Ã§ifte Ã¶deme engellenmeli.

**TERÄ°MLER**

| `Terim` | `AÃ§Ä±klama` | `Ã–rnek` |
| --- | --- | --- | 
| Latency | Gecikme sÃ¼resi(bir isteÄŸin gidiÅŸ-geliÅŸ zamanÄ±) | "Whatsapp mesajÄ± ne kadar sÃ¼rede karÅŸÄ±ya gidiyor?" | 
| Backoff | Hata olduÄŸunda tekrar denemeden Ã¶nce bekleme sÃ¼resi | KapÄ± kilitli -> 1 saniye sonra tekrar dene, yine kilitli -> 2 saniye sonra dene |
| Exponential Backoff | Bekleme sÃ¼resi katlanarak artÄ±yorsa | 1s-> 2s-> 4s-> 8s ÅŸeklinde beklemek |  
| Jitter | Backoff sÃ¼resine rastgelelilik eklemek | 4 saniye beklemesi gerekirken bazen 3.8s veya 4.2 saniye bekletmek | 
| Thundering Herd | BirÃ§ok sistem aynÄ± anda saldÄ±rÄ±ya geÃ§erse oluÅŸturduÄŸu aÅŸÄ±rÄ± yÃ¼k (sÃ¼rÃ¼ psikolojisi problemi) | 100 telefon aynÄ± anda Amazon'a "Åimdi Yenile" dediÄŸinde sistem dÃ¼ÅŸer |
| Enqueue | KuyruÄŸa eklemek | "Bir iÅŸi sonra yap" diye bir listeye yazmak | 

* 1ï¸âƒ£ Circuit breaker hangi Ã¼Ã§ durumda Open olabilir?

- PeÅŸ peÅŸe Ã§ok fazla hata olursa (Ã¶rneÄŸin 10 denemenin 7â€™si hata)
- Timeout sayÄ±sÄ± artarsa (servis cevap vermiyor)
- BaÄŸlantÄ± kurulamazsa (DNS / Network arÄ±zasÄ±)

* 2ï¸âƒ£ Retry stratejisinde jitter neden Ã¶nemlidir?

Ã‡Ã¼nkÃ¼ tÃ¼m sistemler aynÄ± anda tekrar denerse bÃ¼yÃ¼k Ã§Ã¶kÃ¼ÅŸ olur. Jitter kÃ¼Ã§Ã¼k rastgele bekleme koyarak "sÃ¼rÃ¼ halinde saldÄ±rÄ±yÄ±" engeller.

* 3ï¸âƒ£ Bulkhead nedir?

KaynaklarÄ± bÃ¶lmeye denir. Ã–rneÄŸin "Ã¶deme servisine ayrÄ±lmÄ±ÅŸ 20 thread, diÄŸer API' lere 20 thread" diye bÃ¶lmek. BÃ¶ylece Ã¶deme servisi yavaÅŸlasa bile diÄŸer servisleri bozmaz.

